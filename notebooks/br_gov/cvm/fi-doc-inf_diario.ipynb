{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundos de Investimento: Documentos: Informe Diário\n",
    "\n",
    "O INFORME DIÁRIO é um demonstrativo que contém as seguintes informações do fundo, relativas à data de competência:\n",
    "\n",
    "- Valor total da carteira do fundo;\n",
    "- Patrimônio líquido;\n",
    "- Valor da cota;\n",
    "- Captações realizadas no dia;\n",
    "- Resgates pagos no dia;\n",
    "- Número de cotistas\n",
    "\n",
    "**Importante**: A partir de maio/2022, os arquivos de dados de Informe Diário de Fundos passarão a ser disponibilizados no formato csv compactado (zip).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyportela.services.CachedDownload import CachedDownload\n",
    "from datetime import datetime\n",
    "\n",
    "def get_year_url(year: int) -> str:\n",
    "    fileName = f\"inf_diario_fi_{year}.zip\"\n",
    "    url = \"https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/HIST/\" + fileName\n",
    "    return url\n",
    "\n",
    "def get_year_month_url(year: int, month: int) -> str:\n",
    "    fileName = f\"inf_diario_fi_{year}{month:02d}.zip\"\n",
    "    url = \"https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/\" + fileName\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = CachedDownload(\"/tmp/downloads/br_gov/cvm\")\n",
    "expiry = relativedelta(years=1)\n",
    "urls = []\n",
    "\n",
    "\n",
    "def download_history(urls: list):\n",
    "    for year in range(2004, 2021):\n",
    "        url = get_year_url(year)\n",
    "        urls.append(url)\n",
    "        downloads.download(url, expiry)\n",
    "\n",
    "\n",
    "download_history(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_recent_history(urls: list):\n",
    "    dt = datetime(2021, 1, 1)\n",
    "    while dt < datetime.now():\n",
    "        url = get_year_month_url(dt.year, dt.month)\n",
    "        urls.append(url)\n",
    "        downloads.download(url, expiry)\n",
    "        dt = dt + relativedelta(months=1)\n",
    "\n",
    "\n",
    "download_recent_history(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyportela.utils import unzip_to_df\n",
    "from typing import Union, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def to_df(zip_file: Union[str, BytesIO]) -> pd.DataFrame:\n",
    "    df = unzip_to_df(zip_file, sep=\";\", dtype=str)\n",
    "    df[\"DT_COMPTC\"] = df[\"DT_COMPTC\"].apply(\n",
    "        lambda x: datetime.strptime(x, \"%Y-%m-%d\").date()\n",
    "    )\n",
    "    for col in [\n",
    "        \"VL_TOTAL\",\n",
    "        \"VL_QUOTA\",\n",
    "        \"VL_PATRIM_LIQ\",\n",
    "        \"CAPTC_DIA\",\n",
    "        \"RESG_DIA\",\n",
    "        \"NR_COTST\",\n",
    "    ]:\n",
    "        df[col] = df[col].astype(float)\n",
    "    if \"TP_FUNDO\" not in df.columns:\n",
    "        df[\"TP_FUNDO\"] = None\n",
    "    col_names = {}\n",
    "    for col in df.columns:\n",
    "        col_names[col] = col.lower()\n",
    "    df.rename(columns=col_names, inplace=True)\n",
    "    df.Name = \"fi_doc_inf_diario\"\n",
    "    return df\n",
    "\n",
    "\n",
    "# df_2006 = to_df(df_2006_bytes)\n",
    "# df_2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyportela.repositories.PostgresWarehouse import PostgresWarehouse\n",
    "warehouse = PostgresWarehouse(f\"postgresql://postgres:popo8160@localhost:5432/br_gov_cvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/HIST/inf_diario_fi_2018.zip\n",
      "https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/HIST/inf_diario_fi_2019.zip\n",
      "https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/HIST/inf_diario_fi_2020.zip\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_all_data(urls: list):\n",
    "    for url in urls[17:]:\n",
    "        print(url)\n",
    "        #cached = downloads.download(url, expiry)\n",
    "        #df = to_df(cached)\n",
    "        #warehouse.save(df, \"dt_comptc\")\n",
    "        # return 0\n",
    "\n",
    "load_all_data(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "def save_df_to_sqlite(\n",
    "    df: pd.DataFrame,\n",
    "    table_name: str,\n",
    "    db_path: str,\n",
    "    replace_col: Optional[str] = None,\n",
    "    overwrite: bool = False,\n",
    "):\n",
    "    unique_values = None\n",
    "    if replace_col:\n",
    "        unique_values = df[replace_col].unique().tolist()\n",
    "    con = sqlite3.connect(db_path)\n",
    "    try:\n",
    "        if overwrite == True:\n",
    "            return df.to_sql(table_name, con, if_exists=\"replace\", index=False)\n",
    "        elif (\n",
    "            replace_col is not None\n",
    "            and unique_values is not None\n",
    "            and len(unique_values) > 0\n",
    "        ):\n",
    "            sql_where = \", \".join(\"?\" for _ in unique_values)\n",
    "            sql = f\"DELETE FROM {table_name} WHERE {replace_col} IN ({sql_where})\"\n",
    "            con.execute(sql, unique_values).close()\n",
    "        return df.to_sql(table_name, con, if_exists=\"append\", index=False)\n",
    "    finally:\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_df_to_sqlite(df_2006, \"fi_doc_inf_diario\", \"cvm.db\", replace_col=\"DT_COMPTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66951678,)\n",
      "50905\n"
     ]
    }
   ],
   "source": [
    "con = sqlite3.connect(\"cvm.db\")\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT COUNT(*) FROM fi_doc_inf_diario\")\n",
    "print(cur.fetchone())\n",
    "\n",
    "cur.execute(\"SELECT DISTINCT CNPJ_FUNDO FROM fi_doc_inf_diario\")\n",
    "print(len(cur.fetchall()))\n",
    "cur.close()\n",
    "con.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
